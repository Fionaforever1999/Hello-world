import keras
from keras.models import Sequential
from keras.layers import Input, Dense, Dropout, LSTM
from keras.callbacks import ModelCheckpoint
from keras.layers.embeddings import Embedding
from keras.preprocessing import sequence
from keras import optimizers
import numpy as np
import sys#print时会用到


filename='sonnet.txt'
text=open(filename).read().lower()#可以少encode字母，小写字只需要26个字母


print('text length',len(text))

chars =sorted(list(set(text)))#去重字母
print('total chars',len(chars))
print(chars)


chars_indices=dict((c,i)for i,c in enumerate(chars))
indices_chars=dict((i,c)for i,c in enumerate(chars))

import numpy as np#切割文档
import sys
maxlen=40
step=3


sentences=[]
next_chars=[]

for i in range (0,len(sentences)-maxlen,step):
    sentences.append(text[i:i+maxlen])#40个字母
    next_chars.append(text[i+maxlen])#第41个字母generate整个文本

    
    
x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)   #generate zeros with size[number of sentences,40,38]
y = np.zeros((len(sentences), len(chars)), dtype=np.bool) #generate zeros with size[number of sentences,38]

for i, sentence in enumerate(sentences):
    for t, char in enumerate(sentence):
        x[i, t, char_indices[char]] = 1
    y[i, char_indices[next_chars[i]]] = 1

model = Sequential()
model.add(LSTM(128, input_shape=(x.shape[1], x.shape[2])))
model.add(Dense(len(chars), activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer=optimizers.adam())


for iteration in range(1, 11):
    model.fit(x, y,
              batch_size=128,
              epochs=10)
    
# generating text
    print('\nIteration', iteration)
    start_index = np.random.randint(0, len(text) - maxlen - 1)
    sentence = text[start_index: start_index + maxlen]


    for i in range(400):
        x_pred = np.zeros((1, maxlen, len(chars)))
        for t, char in enumerate(sentence):
            x_pred[0, t, char_indices[char]] = 1.

        preds = model.predict(x_pred, verbose=0)[0]      #predict using model, generating a matrix of softmax
        next_index = np.argmax(preds)                    #we want the index with highest probability 
        next_char = indices_char[next_index]             #convert number back to character using the dictionary
        sentence = sentence[1:] + next_char              #append the character predicted to the sentence (start from the second character)

        sys.stdout.write(next_char)                
        sys.stdout.flush()
    print('\n')
